{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a = torch.Tensor([1])\n",
    "b = torch.Tensor([2])\n",
    "c = torch.stack([a,b], dim=0)\n",
    "d = torch.stack([a,b], dim=1)\n",
    "print(c)\n",
    "print(d)\n",
    "```\n",
    "\n",
    "```python\n",
    "x = torch.randn([32,3,256,256])\n",
    "```\n",
    "\n",
    "Formula for output size for Convolutions:\n",
    "$[(Wâˆ’K+2P)/S]+1$\n",
    "\n",
    "For transpose convolution (which upsample there is also `output_padding` that fills only one-side (useful for those 'same' paddings). \n",
    "It is a non-symetric padding of the output image that enables us to get an even size image.\n",
    "        \n",
    "\n",
    "Fun fact: Conv2D `Module` initializes all parametres, [functional form](https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html) can take weight (i.e. kernel) as the input.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
